{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100450,
     "status": "ok",
     "timestamp": 1610708848049,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "FSUbmrwYUJTM",
    "outputId": "817d81ea-435b-4b77-d449-f96ba7139408"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/My Drive/Data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run lllor pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100444,
     "status": "ok",
     "timestamp": 1610708848050,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "iMiEEegeUNeR",
    "outputId": "81114495-54ca-4dbb-9837-2d216d7da53f"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"Data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103071,
     "status": "ok",
     "timestamp": 1610708850683,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "Duw_HqqUUOMU"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"Data/train_data/\"\n",
    "TEST_DATA_PATH =\"Data/test_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103067,
     "status": "ok",
     "timestamp": 1610708850683,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "G8geK_7vUP6e"
   },
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 105648,
     "status": "ok",
     "timestamp": 1610708853268,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "Fu7ORXSlUSBE"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "def save_net(fname, net):\n",
    "    with h5py.File(fname, 'w') as h5f:\n",
    "        for k, v in net.state_dict().items():\n",
    "            h5f.create_dataset(k, data=v.cpu().numpy())\n",
    "def load_net(fname, net):\n",
    "    with h5py.File(fname, 'r') as h5f:\n",
    "        for k, v in net.state_dict().items():        \n",
    "            param = torch.from_numpy(np.asarray(h5f[k]))         \n",
    "            v.copy_(param)\n",
    "            \n",
    "def save_checkpoint(state, is_best,task_id, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, task_id+filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(task_id+filename, task_id+'model_best.pth.tar')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 105645,
     "status": "ok",
     "timestamp": 1610708853269,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "zkBe7RmXUUTy"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "contain dummy args with config\n",
    "helpfull for copy paste Kaggle\n",
    "\"\"\"\n",
    "import argparse\n",
    "\n",
    "\n",
    "def make_args(train_json= \"\", test_json=\"\", pre=\"\", gpu=\"0\", task=\"task_one_\"):\n",
    "    \"\"\"\n",
    "    these arg does not have any required commandline arg (all with default value)\n",
    "    :param train_json:\n",
    "    :param test_json:\n",
    "    :param pre:\n",
    "    :param gpu:\n",
    "    :param task:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='PyTorch CSRNet')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.gpu = gpu\n",
    "    args.task = task\n",
    "    args.pre = None\n",
    "    return args\n",
    "\n",
    "\n",
    "class Meow():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def make_meow_args(gpu=\"0\", task=\"task_one_\"):\n",
    "    args = Meow()\n",
    "    args.gpu = gpu\n",
    "    args.task = task\n",
    "    args.pre = None\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 106428,
     "status": "ok",
     "timestamp": 1610708854056,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "DFAMlVrUUW_P"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\"\"\"\n",
    "create a list of file (full directory)\n",
    "\"\"\"\n",
    "\n",
    "def create_training_image_list(data_path):\n",
    "    \"\"\"\n",
    "    create a list of absolutely path of jpg file\n",
    "    :param data_path: must contain subfolder \"images\" with *.jpg  (example ShanghaiTech/part_A/train_data/)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    DATA_PATH = data_path\n",
    "    image_path_list = glob.glob(os.path.join(DATA_PATH, \"images\", \"*.jpg\"))\n",
    "    return image_path_list\n",
    "\n",
    "def get_train_val_list(data_path):\n",
    "    DATA_PATH = data_path\n",
    "    image_path_list = glob.glob(os.path.join(DATA_PATH, \"images\", \"*.jpg\"))\n",
    "    train, val = train_test_split(image_path_list, test_size=0.3, random_state=113)\n",
    "\n",
    "    print(\"train size \", len(train))\n",
    "    print(\"val size \", len(val))\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 106879,
     "status": "ok",
     "timestamp": 1610708854511,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "Op2Q6phZUY-s"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from PIL import Image,ImageFilter,ImageDraw\n",
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import ImageStat\n",
    "import cv2\n",
    "\n",
    "def load_data(img_path,train = True):\n",
    "    gt_path = img_path.replace('.jpg','.h5').replace('images','ground-truth')\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    gt_file = h5py.File(gt_path, 'r')\n",
    "    target = np.asarray(gt_file['density'])\n",
    "\n",
    "    target = cv2.resize(target,(int(target.shape[1]/8), int(target.shape[0]/8)),interpolation = cv2.INTER_CUBIC)*64\n",
    "    \n",
    "    return img,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 106876,
     "status": "ok",
     "timestamp": 1610708854511,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "B1cTobUyUa12"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "class ListDataset(Dataset):\n",
    "    def __init__(self, root, shape=None, shuffle=True, transform=None,  train=False, seen=0, batch_size=1, num_workers=4):\n",
    "        \"\"\"\n",
    "        if you have different image size, then batch_size must be 1\n",
    "        :param root:\n",
    "        :param shape:\n",
    "        :param shuffle:\n",
    "        :param transform:\n",
    "        :param train:\n",
    "        :param seen:\n",
    "        :param batch_size:\n",
    "        :param num_workers:\n",
    "        \"\"\"\n",
    "        if train:\n",
    "            root = root *2\n",
    "        if shuffle:\n",
    "            random.shuffle(root)\n",
    "        \n",
    "        self.nSamples = len(root)\n",
    "        self.lines = root\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.shape = shape\n",
    "        self.seen = seen\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.nSamples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert index <= len(self), 'index range error' \n",
    "        \n",
    "        img_path = self.lines[index]\n",
    "        \n",
    "        img,target = load_data(img_path,self.train)\n",
    "        \n",
    "        #img = 255.0 * F.to_tensor(img)\n",
    "        \n",
    "        #img[0,:,:]=img[0,:,:]-92.8207477031\n",
    "        #img[1,:,:]=img[1,:,:]-95.2757037428\n",
    "        #img[2,:,:]=img[2,:,:]-104.877445883\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 106872,
     "status": "ok",
     "timestamp": 1610708854512,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "fVK7n8IJPINm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 107214,
     "status": "ok",
     "timestamp": 1610708854858,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "efoXAZ6Fj4fw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, NL='relu', same_padding=False, bn=False):\n",
    "        super(Conv2d, self).__init__()\n",
    "        padding = int((kernel_size - 1) / 2) if same_padding else 0\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True) if bn else None\n",
    "        if NL == 'relu':\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "        elif NL == 'prelu':\n",
    "            self.relu = nn.PReLU()\n",
    "        elif NL == 'lrelu':\n",
    "            self.relu = nn.LeakyReLU(0.2, True)\n",
    "        else:\n",
    "            self.relu = None\t\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FC(nn.Module):\n",
    "    def __init__(self, in_features, out_features, relu=True):\n",
    "        super(FC, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "        self.relu = nn.ReLU(inplace=True) if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def save_net(fname, net):\n",
    "    import h5py\n",
    "    with h5py.File(fname, mode='w') as h5f:\n",
    "        for k, v in net.state_dict().items():\n",
    "            #if 'module' in k:\n",
    "            #    k = k.replace('.module','.')\n",
    "            h5f.create_dataset(k, data=v.cpu().numpy())\n",
    "\n",
    "\n",
    "def load_net(fname, net):\n",
    "    import h5py\n",
    "    with h5py.File(fname, mode='r') as h5f:\n",
    "        for k, v in net.state_dict().items():        \n",
    "            #print(k)\n",
    "            param = torch.from_numpy(np.asarray(h5f[k]))         \n",
    "            v.copy_(param)\n",
    "\n",
    "\n",
    "def np_to_variable(x, is_cuda=True, is_training=False, dtype=torch.FloatTensor):\n",
    "    if is_training:\n",
    "        v = Variable(torch.from_numpy(x).type(dtype))\n",
    "    else:\n",
    "        v = Variable(torch.from_numpy(x).type(dtype), requires_grad = False, volatile = True)\n",
    "    if is_cuda:\n",
    "        v = v.cuda()\n",
    "    return v\n",
    "\n",
    "def to_variable(x, is_cuda=True, is_training=False):\n",
    "    if is_training:\n",
    "        v = Variable(x)\n",
    "    else:\n",
    "        v = Variable(x, requires_grad = False, volatile = True)\n",
    "    if is_cuda:\n",
    "        v = v.cuda()\n",
    "    return v\n",
    "    \n",
    "\n",
    "def set_trainable(model, requires_grad):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad\n",
    "\n",
    "\n",
    "def weights_normal_init(model, dev=0.01):\n",
    "    if isinstance(model, list):\n",
    "        for m in model:\n",
    "            weights_normal_init(m, dev)\n",
    "    else:\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Conv2d):                \n",
    "                #print torch.sum(m.weight)\n",
    "                m.weight.data.normal_(0.0, dev)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0.0, dev)\n",
    "            elif isinstance(m, nn.PReLU):\n",
    "                m.weight.data.fill_(0.001)\n",
    "\n",
    "\n",
    "# put i-th map to the top\n",
    "def to_top(data, i):\n",
    "    temp = data\n",
    "    if(i == 0):                                                                                                                 \n",
    "        return temp\n",
    "    temp[0,:,:,:,] = data[i,:,:,:]\n",
    "    temp[i,:,:,:,] = data[0,:,:,:]\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 107569,
     "status": "ok",
     "timestamp": 1610708855219,
     "user": {
      "displayName": "omar elharrouss",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGC_l4X-u1jl7ka6nlFmF9bP8pq1h8yOVXg_Wvg=s64",
      "userId": "07323381654864768298"
     },
     "user_tz": -180
    },
    "id": "wFalquZDh5Be",
    "outputId": "3e78c0c5-4a9a-4705-e250-4d3e229b421f"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "def save_net(fname, net):\n",
    "    with h5py.File(fname, 'w') as h5f:\n",
    "        for k, v in net.state_dict().items():\n",
    "            h5f.create_dataset(k, data=v.cpu().numpy())\n",
    "def load_net(fname, net):\n",
    "    with h5py.File('./saved_models'+fname, 'r') as h5f:\n",
    "        for k, v in net.state_dict().items():        \n",
    "            param = torch.from_numpy(np.asarray(h5f[k]))         \n",
    "            v.copy_(param)\n",
    "            \n",
    "def save_checkpoint(state, is_best,task_id, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, './saved_models/'+task_id+filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile('./saved_models/'+task_id+filename, './saved_models/'+task_id+'model_best.pth.tar')            \n",
    "\n",
    "def tv_loss(y):\n",
    "    loss = torch.sum((y[:-1, :, :, :] - y[1:, :, :, :])**2) + torch.sum((y[:, :-1, :, :] - y[:, 1:, :, :])**2)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as standard_transforms\n",
    "\n",
    "def initialize_weights(models):\n",
    "    for model in models:\n",
    "        real_init_weights(model)\n",
    "\n",
    "\n",
    "def real_init_weights(m):\n",
    "\n",
    "    if isinstance(m, list):\n",
    "        for mini_m in m:\n",
    "            real_init_weights(mini_m)\n",
    "    else:\n",
    "        if isinstance(m, nn.Conv2d):    \n",
    "            nn.init.normal_(m.weight, std=0.01)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0.0, std=0.01)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m,nn.Module):\n",
    "            for mini_m in m.children():\n",
    "                real_init_weights(mini_m)\n",
    "        else:\n",
    "            print( m )\n",
    "\n",
    "def weights_normal_init(*models):\n",
    "    for model in models:\n",
    "        dev=0.01\n",
    "        if isinstance(model, list):\n",
    "            for m in model:\n",
    "                weights_normal_init(m, dev)\n",
    "        else:\n",
    "            for m in model.modules():            \n",
    "                if isinstance(m, nn.Conv2d):        \n",
    "                    m.weight.data.normal_(0.0, dev)\n",
    "                    if m.bias is not None:\n",
    "                        m.bias.data.fill_(0.0)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    m.weight.data.normal_(0.0, dev)\n",
    "\n",
    "\n",
    "def logger(exp_path, exp_name, work_dir, exception, resume=False):\n",
    "\n",
    "    from tensorboardX import SummaryWriter\n",
    "    \n",
    "    if not os.path.exists(exp_path):\n",
    "        os.mkdir(exp_path)\n",
    "    writer = SummaryWriter(exp_path+ '/' + exp_name)\n",
    "    log_file = exp_path + '/' + exp_name + '/' + exp_name + '.txt'\n",
    "    \n",
    "    cfg_file = open('./config.py',\"r\")  \n",
    "    cfg_lines = cfg_file.readlines()\n",
    "    \n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(''.join(cfg_lines) + '\\n\\n\\n\\n')\n",
    "\n",
    "    if not resume:\n",
    "        copy_cur_env(work_dir, exp_path+ '/' + exp_name + '/code', exception)\n",
    "\n",
    "    return writer, log_file\n",
    "\n",
    "\n",
    "def logger_txt(log_file,epoch,scores):\n",
    "\n",
    "    mae, mse, nae, loss = scores\n",
    "\n",
    "    snapshot_name = 'all_ep_%d_mae_%.1f_mse_%.1f' % (epoch + 1, mae, mse)\n",
    "\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write('='*15 + '+'*15 + '='*15 + '\\n\\n')\n",
    "        f.write(snapshot_name + '\\n')\n",
    "        f.write('    [mae %.2f mse %.2f nae %.4f], [val loss %.4f]\\n' % (mae, mse, nae, loss))\n",
    "        f.write('='*15 + '+'*15 + '='*15 + '\\n\\n')    \n",
    "\n",
    "\n",
    "def vis_results(exp_name, epoch, writer, restore, img, pred_map, gt_map):\n",
    "\n",
    "    pil_to_tensor = standard_transforms.ToTensor()\n",
    "\n",
    "    x = []\n",
    "    \n",
    "    for idx, tensor in enumerate(zip(img.cpu().data, pred_map, gt_map)):\n",
    "        if idx>1:# show only one group\n",
    "            break\n",
    "\n",
    "        pil_input = restore(tensor[0])\n",
    "        \n",
    "        pred_color_map = cv2.applyColorMap((255*tensor[1]/(tensor[2].max()+1e-10)).astype(np.uint8).squeeze(), cv2.COLORMAP_JET)\n",
    "        gt_color_map = cv2.applyColorMap((255*tensor[2]/(tensor[2].max()+1e-10)).astype(np.uint8).squeeze(), cv2.COLORMAP_JET)\n",
    "        pil_label = Image.fromarray(cv2.cvtColor(gt_color_map,cv2.COLOR_BGR2RGB))\n",
    "        pil_output = Image.fromarray(cv2.cvtColor(pred_color_map,cv2.COLOR_BGR2RGB))\n",
    "        x.extend([pil_to_tensor(pil_input.convert('RGB')), pil_to_tensor(pil_label.convert('RGB')), pil_to_tensor(pil_output.convert('RGB'))])\n",
    "\n",
    "    x = torch.stack(x, 0)\n",
    "    x = vutils.make_grid(x, nrow=3, padding=5)\n",
    "    x = (x.numpy()*255).astype(np.uint8)\n",
    "\n",
    "    writer.add_image(exp_name + '_epoch_' + str(epoch+1), x)\n",
    "\n",
    "\n",
    "def print_NWPU_summary(exp_name,log_txt,epoch, scores,train_record,c_maes,c_mses,c_naes):\n",
    "    mae, mse, nae, loss = scores\n",
    "    c_mses['level'] = np.sqrt(c_mses['level'].avg)\n",
    "    c_mses['illum'] = np.sqrt(c_mses['illum'].avg)\n",
    "\n",
    "    with open(log_txt, 'a') as f:\n",
    "        f.write('='*15 + '+'*15 + '='*15 + '\\n')\n",
    "        f.write(str(epoch) + '\\n\\n')\n",
    "\n",
    "        f.write('  [mae %.4f mse %.4f nae %.4f], [val loss %.4f]\\n\\n' % (mae, mse, nae, loss))\n",
    "        f.write('  [level: mae %.4f mse %.4f nae %.4f]\\n' % (np.average(c_maes['level'].avg), np.average(c_mses['level']), np.sum(c_naes['level'].avg)/4))\n",
    "        f.write('    list: ' + str(np.transpose(c_maes['level'].avg)) + '\\n')\n",
    "        f.write('    list: ' + str(np.transpose(c_mses['level'])) + '\\n\\n')\n",
    "        f.write('    list: ' + str(np.transpose(c_naes['level'].avg)) + '\\n\\n')\n",
    "\n",
    "        f.write('  [illum: mae %.4f mse %.4f nae %.4f]\\n' % (np.average(c_maes['illum'].avg), np.average(c_mses['illum']), np.sum(c_naes['illum'].avg)/4))\n",
    "        f.write('    list: ' + str(np.transpose(c_maes['illum'].avg)) + '\\n')\n",
    "        f.write('    list: ' + str(np.transpose(c_mses['illum'])) + '\\n\\n')\n",
    "        f.write('    list: ' + str(np.transpose(c_naes['illum'].avg)) + '\\n\\n')\n",
    "\n",
    "\n",
    "        f.write('='*15 + '+'*15 + '='*15 + '\\n\\n')\n",
    "\n",
    "    print( '='*50 )\n",
    "    print( exp_name )\n",
    "    print( '    '+ '-'*20 )\n",
    "    print( '    [mae %.2f mse %.2f], [val loss %.4f]' % (mae, mse, loss) )\n",
    "    print( '    '+ '-'*20 )\n",
    "    print( '[best] [model: %s] , [mae %.2f], [mse %.2f], [nae %.4f]' % (train_record['best_model_name'],\\\n",
    "                                                        train_record['best_mae'],\\\n",
    "                                                        train_record['best_mse'],\\\n",
    "                                                        train_record['best_nae']) )\n",
    "    print( '='*50 )  \n",
    "\n",
    "\n",
    "def update_model(net,optimizer,scheduler,epoch,i_tb,exp_path,exp_name,scores,train_record,log_file=None):\n",
    "\n",
    "    mae, mse, nae, loss = scores\n",
    "\n",
    "    snapshot_name = 'all_ep_%d_mae_%.1f_mse_%.1f_nae_%.3f' % (epoch + 1, mae, mse, nae)\n",
    "\n",
    "    if mae < train_record['best_mae'] or mse < train_record['best_mse'] or nae < train_record['best_nae']:   \n",
    "        train_record['best_model_name'] = snapshot_name\n",
    "        if log_file is not None:\n",
    "            logger_txt(log_file,epoch,scores)\n",
    "        to_saved_weight = net.state_dict()\n",
    "        torch.save(to_saved_weight, os.path.join(exp_path, exp_name, snapshot_name + '.pth'))\n",
    "\n",
    "    if mae < train_record['best_mae']:           \n",
    "        train_record['best_mae'] = mae\n",
    "    if mse < train_record['best_mse']:\n",
    "        train_record['best_mse'] = mse \n",
    "    if nae < train_record['best_nae']:\n",
    "        train_record['best_nae'] = nae \n",
    "\n",
    "    latest_state = {'train_record':train_record, 'net':net.state_dict(), 'optimizer':optimizer.state_dict(),\\\n",
    "                    'scheduler':scheduler.state_dict(), 'epoch': epoch, 'i_tb':i_tb, 'exp_path':exp_path, \\\n",
    "                    'exp_name':exp_name}\n",
    "\n",
    "    torch.save(latest_state,os.path.join(exp_path, exp_name, 'latest_state.pth'))\n",
    "\n",
    "    return train_record\n",
    "\n",
    "\n",
    "def copy_cur_env(work_dir, dst_dir, exception):\n",
    "\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.mkdir(dst_dir)\n",
    "\n",
    "    for filename in os.listdir(work_dir):\n",
    "\n",
    "        file = os.path.join(work_dir,filename)\n",
    "        dst_file = os.path.join(dst_dir,filename)\n",
    "\n",
    "        if os.path.isdir(file) and exception not in filename:\n",
    "            shutil.copytree(file, dst_file)\n",
    "        elif os.path.isfile(file):\n",
    "            shutil.copyfile(file,dst_file)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, cur_val):\n",
    "        self.cur_val = cur_val\n",
    "        self.sum += cur_val\n",
    "        self.count += 1\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class AverageCategoryMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self,num_class):        \n",
    "        self.num_class = num_class\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_val = np.zeros(self.num_class)\n",
    "        self.avg = np.zeros(self.num_class)\n",
    "        self.sum = np.zeros(self.num_class)\n",
    "        self.count = np.zeros(self.num_class)\n",
    "\n",
    "    def update(self, cur_val, class_id):\n",
    "        self.cur_val[class_id] = cur_val\n",
    "        self.sum[class_id] += cur_val\n",
    "        self.count[class_id] += 1\n",
    "        self.avg[class_id] = self.sum[class_id] / self.count[class_id]\n",
    "\n",
    "\n",
    "class Timer(object):\n",
    "    \"\"\"A simple timer.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_time = 0.\n",
    "        self.calls = 0\n",
    "        self.start_time = 0.\n",
    "        self.diff = 0.\n",
    "        self.average_time = 0.\n",
    "\n",
    "    def tic(self):\n",
    "        # using time.time instead of time.clock because time time.clock\n",
    "        # does not normalize for multithreading\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def toc(self, average=True):\n",
    "        self.diff = time.time() - self.start_time\n",
    "        self.total_time += self.diff\n",
    "        self.calls += 1\n",
    "        self.average_time = self.total_time / self.calls\n",
    "        if average:\n",
    "            return self.average_time\n",
    "        else:\n",
    "            return self.diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pdb\n",
    "\n",
    "class convDU(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "        in_out_channels=64,\n",
    "        kernel_size=(9,1)\n",
    "        ):\n",
    "        super(convDU, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_out_channels, in_out_channels, kernel_size, stride=1, padding=((kernel_size[0]-1)/2,(kernel_size[1]-1)/2)),\n",
    "            nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "    def forward(self, fea):\n",
    "        n, c, h, w = fea.size()\n",
    "\n",
    "        fea_stack = []\n",
    "        for i in range(h):\n",
    "            i_fea = fea.select(2, i).resize(n,c,1,w)\n",
    "            if i == 0:\n",
    "                fea_stack.append(i_fea)\n",
    "                continue\n",
    "            fea_stack.append(self.conv(fea_stack[i-1])+i_fea)\n",
    "            # pdb.set_trace()\n",
    "            # fea[:,i,:,:] = self.conv(fea[:,i-1,:,:].expand(n,1,h,w))+fea[:,i,:,:].expand(n,1,h,w)\n",
    "\n",
    "\n",
    "        for i in xrange(h):\n",
    "            pos = h-i-1\n",
    "            if pos == h-1:\n",
    "                continue\n",
    "            fea_stack[pos] = self.conv(fea_stack[pos+1])+fea_stack[pos]\n",
    "        # pdb.set_trace()\n",
    "        fea = torch.cat(fea_stack, 2)\n",
    "        return fea\n",
    "\n",
    "class convLR(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "        in_out_channels=64,\n",
    "        kernel_size=(1,9)\n",
    "        ):\n",
    "        super(convLR, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_out_channels, in_out_channels, kernel_size, stride=1, padding=((kernel_size[0]-1)/2,(kernel_size[1]-1)/2)),\n",
    "            nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "    def forward(self, fea):\n",
    "        n, c, h, w = fea.size()\n",
    "\n",
    "        fea_stack = []\n",
    "        for i in range(w):\n",
    "            i_fea = fea.select(3, i).resize(n,c,h,1)\n",
    "            if i == 0:\n",
    "                fea_stack.append(i_fea)\n",
    "                continue\n",
    "            fea_stack.append(self.conv(fea_stack[i-1])+i_fea)\n",
    "\n",
    "        for i in range(w):\n",
    "            pos = w-i-1\n",
    "            if pos == w-1:\n",
    "                continue\n",
    "            fea_stack[pos] = self.conv(fea_stack[pos+1])+fea_stack[pos]\n",
    "\n",
    "\n",
    "        fea = torch.cat(fea_stack, 3)\n",
    "        return fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import pdb\n",
    "\n",
    "#model_path = 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'\n",
    "\n",
    "class resSFCN(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(resSFCN, self).__init__()\n",
    "        self.seen = 0\n",
    "        self.backend_feat  = [512, 512, 512,256,128,64]\n",
    "        self.frontend = []\n",
    "        \n",
    "        self.backend = make_layers(self.backend_feat,in_channels = 1024,dilation = True)\n",
    "        #self.convDU = nn.Conv2d(64, 64, kernel_size=3, stride=1,padding=1, bias=False)\n",
    "        #self.convLR = nn.Conv2d(64, 64, kernel_size=3, stride=1,padding=1, bias=False)\n",
    "\n",
    "\n",
    "        self.output_layer = nn.Sequential(nn.Conv2d(64, 1, kernel_size=1),nn.ReLU())\n",
    "\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        res = models.resnet101()\n",
    "        #pre_wts = torch.load(model_path)\n",
    "        #res.load_state_dict(pre_wts)\n",
    "        self.frontend = nn.Sequential(\n",
    "            res.conv1, res.bn1, res.relu, res.maxpool, res.layer1, res.layer2\n",
    "        )\n",
    "        self.own_reslayer_3 = make_res_layer(Bottleneck, 256, 23, stride=1)        \n",
    "        self.own_reslayer_3.load_state_dict(res.layer3.state_dict())\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.frontend(x)\n",
    "        #print(\"frant\",x.size())\n",
    "        x = self.own_reslayer_3(x)\n",
    "        #print(\"own\",x.size())\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        x = self.backend(x)\n",
    "        #print(\"back\",x.size())\n",
    "        #x = self.convDU(x)\n",
    "        #x = self.convLR(x)\n",
    "        x = self.output_layer(x)\n",
    "        #print(\"x\",x.size())\n",
    "\n",
    "        #x = F.upsample(x,scale_factor=8)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.fill_(1)\n",
    "                m.bias.data.fill_(0)\n",
    "            \n",
    "                \n",
    "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
    "    if dilation:\n",
    "        d_rate = 2\n",
    "    else:\n",
    "        d_rate = 1\n",
    "    layers = []\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate,dilation = d_rate)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)      \n",
    "\n",
    "\n",
    "def make_res_layer(block, planes, blocks, stride=1):\n",
    "\n",
    "    downsample = None\n",
    "    inplanes=512\n",
    "    if stride != 1 or inplanes != planes * block.expansion:\n",
    "        downsample = nn.Sequential(\n",
    "            nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                      kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(planes * block.expansion),\n",
    "        )\n",
    "\n",
    "    layers = []\n",
    "    layers.append(block(inplanes, planes, stride, downsample))\n",
    "    inplanes = planes * block.expansion\n",
    "    for i in range(1, blocks):\n",
    "        layers.append(block(inplanes, planes))\n",
    "\n",
    "    return nn.Sequential(*layers)  \n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "spn = resSFCN()\n",
    "#spn = VGG()\n",
    "print(spn)\n",
    "\n",
    "model = resSFCN()\n",
    "x = torch.randn(1, 3, 768, 1024)\n",
    "\n",
    "# Let's print it\n",
    "model(x)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqxtOhfcUqco",
    "outputId": "cc97e778-a04e-47f5-ef80-37e67894fedf"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "# import from library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "A dublicate of train.py \n",
    "However it does not need commandline arg\n",
    "\"\"\"\n",
    "def main():\n",
    "    global args, best_prec1\n",
    "    args = make_meow_args()\n",
    "\n",
    "\n",
    "    best_prec1 = 1e6\n",
    "\n",
    "    args.original_lr = 1e-7\n",
    "    args.lr = 1e-7\n",
    "    args.batch_size = 1\n",
    "    args.momentum = 0.95\n",
    "    args.decay = 5 * 1e-4\n",
    "    args.start_epoch = 0\n",
    "    args.epochs = 100\n",
    "    args.steps = [-1, 1, 100, 150]\n",
    "    args.scales = [1, 1, 1, 1]\n",
    "    args.workers = 4\n",
    "    args.seed = time.time()\n",
    "    args.print_freq = 30\n",
    "    args.pre = PRETRAINED_MODEL\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "    train_list, val_list = get_train_val_list(DATA_PATH)\n",
    "\n",
    "    model = resSFCN()\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "    criterion = nn.MSELoss(size_average=False).cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.decay)\n",
    "\n",
    "    if args.pre:\n",
    "        if os.path.isfile(args.pre):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.pre))\n",
    "            checkpoint = torch.load(args.pre)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.pre, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.pre))\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        train(train_list, model, criterion, optimizer, epoch)\n",
    "        prec1 = validate(val_list, model, criterion)\n",
    "        is_best = prec1 < best_prec1\n",
    "        best_prec1 = min(prec1, best_prec1)\n",
    "        print(' * best MAE {mae:.3f} '\n",
    "              .format(mae=best_prec1))\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': args.pre,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, args.task)\n",
    "\n",
    "\n",
    "def train(train_list, model, criterion, optimizer, epoch):\n",
    "    losses = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ListDataset(train_list,\n",
    "                            shuffle=True,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                            std=[0.229, 0.224, 0.225]),\n",
    "                            ]),\n",
    "                            train=True,\n",
    "                            seen=model.seen,\n",
    "                            batch_size=args.batch_size,\n",
    "                            num_workers=args.workers),\n",
    "        batch_size=args.batch_size)\n",
    "    print('epoch %d, processed %d samples, lr %.10f' % (epoch, epoch * len(train_loader.dataset), args.lr))\n",
    "\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    for i, (img, target) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        img = img.cuda()\n",
    "        img = Variable(img)\n",
    "        output = model(img)\n",
    "\n",
    "        target = target.type(torch.FloatTensor).unsqueeze(0).cuda()\n",
    "        target = Variable(target)\n",
    "        \n",
    "        #print('out ', output.size(),' tar ',target.size())\n",
    "        #target.reshape([1, 1, 34, 120]) #out[1, 1, 34, 120])#tar[1, 1, 67, 120]\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        losses.update(loss.item(), img.size(0))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                .format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses))\n",
    "\n",
    "\n",
    "def validate(val_list, model, criterion):\n",
    "    print('begin test')\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        ListDataset(val_list,\n",
    "                            shuffle=False,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                            std=[0.229, 0.224, 0.225]),\n",
    "                            ]), train=False),\n",
    "        batch_size=args.batch_size)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    mae = 0\n",
    "\n",
    "    for i, (img, target) in enumerate(test_loader):\n",
    "        img = img.cuda()\n",
    "        img = Variable(img)\n",
    "        output = model(img)\n",
    "\n",
    "        mae += abs(output.data.sum() - target.sum().type(torch.FloatTensor).cuda())\n",
    "        #print('kkkk',format(mae))\n",
    "\n",
    "    mae = mae / len(test_loader)\n",
    "    print(' * MAE {mae:.3f} '\n",
    "          .format(mae=mae))\n",
    "\n",
    "    return mae\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "\n",
    "    args.lr = args.original_lr\n",
    "\n",
    "    for i in range(len(args.steps)):\n",
    "\n",
    "        scale = args.scales[i] if i < len(args.scales) else 1\n",
    "\n",
    "        if epoch >= args.steps[i]:\n",
    "            args.lr = args.lr * scale\n",
    "            if epoch == args.steps[i]:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = args.lr\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLAzw3sKkVq_"
   },
   "outputs": [],
   "source": [
    "test_image_list = create_training_image_list(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LT1ygH9xkXqj"
   },
   "outputs": [],
   "source": [
    "best_checkpoint = torch.load(\"task_one_checkpoint.pth.tar\")\n",
    "model = resSFCN()\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.decay)\n",
    "criterion = nn.MSELoss(size_average=False).cuda()\n",
    "model.load_state_dict(best_checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(best_checkpoint['optimizer'])\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhBKNXiNkYQw"
   },
   "outputs": [],
   "source": [
    "test_result = validate(test_image_list, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWQuhpPWkaUw"
   },
   "outputs": [],
   "source": [
    "best_checkpoint = torch.load(\"task_one_model_best.pth.tar\")\n",
    "model = resSFCN()\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.decay)\n",
    "criterion = nn.MSELoss(size_average=False).cuda()\n",
    "model.load_state_dict(best_checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(best_checkpoint['optimizer'])\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yp2G4LjZkeBN"
   },
   "outputs": [],
   "source": [
    "test_result = validate(test_image_list, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKVJ3Z1gbmXL"
   },
   "outputs": [],
   "source": [
    "val_list=create_training_image_list(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFAKDwOZbZ4A"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# importing libraries\n",
    "import h5py\n",
    "import scipy.io as io\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import scipy\n",
    "import json\n",
    "from matplotlib import cm as CM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "                   ])\n",
    "model = resSFCN()\n",
    "model = model.cuda()\n",
    "checkpoint = torch.load('./task_one_model_best.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBOFQTwqbZ7_"
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm as c\n",
    "for i in range(len(val_list)):\n",
    "    print('frame:',i)\n",
    "    #print('kkkk',os.path.splitext(os.path.basename(val_list[i]))[0])\n",
    "    ll=os.path.splitext(os.path.basename(val_list[i]))[0]\n",
    "    img = transform(Image.open(val_list[i]).convert('RGB')).cuda()\n",
    "    output = model(img.unsqueeze(0))\n",
    "    #print(\"Predicted Count : \",int(output.detach().cpu().sum().numpy()))\n",
    "    temp = np.asarray(output.detach().cpu().reshape(output.detach().cpu().shape[2],output.detach().cpu().shape[3]))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(int(output.detach().cpu().sum().numpy()))\n",
    "    plt.imshow(temp,cmap = c.jet)\n",
    "    plt.savefig('./data_results/SCNet_'+ ll + '.png')\n",
    "    plt.show()\n",
    "    \n",
    "    temp = h5py.File('./Data/test_data/ground-truth/' + ll + '.h5', 'r')\n",
    "    temp_1 = np.asarray(temp['density'])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(int(np.sum(temp_1)) + 1)\n",
    "    plt.imshow(temp_1,cmap = c.jet)\n",
    "    plt.savefig('./data_results/'+ ll + '_GT.png')\n",
    "    print(\"Original Count : \",int(np.sum(temp_1)) + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SCNet_Noise.ipynb",
   "provenance": [
    {
     "file_id": "1lwhIWmPtuRTVxjbFNTvJ6eCxwiA31bap",
     "timestamp": 1610365456444
    },
    {
     "file_id": "12vU-c_ylj7TGKPcKLvGfvzXvumJsFbE1",
     "timestamp": 1593574342224
    },
    {
     "file_id": "1RML6_NrScU6kToBp0PXBxnq0VVQM6EZk",
     "timestamp": 1593037402983
    },
    {
     "file_id": "1DBHeyiUkLWx7Z3v0IqUm66OYI1-5scpC",
     "timestamp": 1592901670352
    },
    {
     "file_id": "1Apn_K4xy2GD1dhj-dXZXvi2JyIP3wZs5",
     "timestamp": 1592883244181
    },
    {
     "file_id": "11J0BP6gh3z0Tm8goj-nqO_kpwS6vDJxy",
     "timestamp": 1592871323270
    },
    {
     "file_id": "1YkjWuzbj9f_Fib8QxAQ13VPaERIqZTR0",
     "timestamp": 1592728935157
    },
    {
     "file_id": "1fC6sSVameLJqz30S2pks_565pdGXjurs",
     "timestamp": 1592627209425
    },
    {
     "file_id": "1Su3hgh6k005ooGJFGZlVkXib8Hwsvgc2",
     "timestamp": 1592507243771
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
